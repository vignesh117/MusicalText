We are built out of very small stuff, and we are embedded in a very large cosmos, and the fact is that we are not very good at understanding reality at either of those scales, and that's because our brains haven't evolved to understand the world at that scale.
Instead, we're trapped on this very thin slice of perception right in the middle. But it gets strange, because even at that slice of reality that we call home, we're not seeing most of the action that's going on. So take the colors of our world. This is light waves, electromagnetic radiation that bounces off objects and it hits specialized receptors in the back of our eyes. But we're not seeing all the waves out there. In fact, what we see is less than a 10 trillionth of what's out there. So you have radio waves and microwaves and X-rays and gamma rays passing through your body right now and you're completely unaware of it, because you don't come with the proper biological receptors for picking it up. There are thousands of cell phone conversations passing through you right now, and you're utterly blind to it.
Now, it's not that these things are inherently unseeable. Snakes include some infrared in their reality, and honeybees include ultraviolet in their view of the world, and of course we build machines in the dashboards of our cars to pick up on signals in the radio frequency range, and we built machines in hospitals to pick up on the X-ray range. But you can't sense any of those by yourself, at least not yet, because you don't come equipped with the proper sensors.
Now, what this means is that our experience of reality is constrained by our biology, and that goes against the common sense notion that our eyes and our ears and our fingertips are just picking up the objective reality that's out there. Instead, our brains are sampling just a little bit of the world.
Now, across the animal kingdom, different animals pick up on different parts of reality. So in the blind and deaf world of the tick, the important signals are temperature and butyric acid; in the world of the black ghost knifefish, its sensory world is lavishly colored by electrical fields; and for the echolocating bat, its reality is constructed out of air compression waves. That's the slice of their ecosystem that they can pick up on, and we have a word for this in science. It's called the umwelt, which is the German word for the surrounding world. Now, presumably, every animal assumes that its umwelt is the entire objective reality out there, because why would you ever stop to imagine that there's something beyond what we can sense. Instead, what we all do is we accept reality as it's presented to us.
Let's do a consciousness-raiser on this. Imagine that you are a bloodhound dog. Your whole world is about smelling. You've got a long snout that has 200 million scent receptors in it, and you have wet nostrils that attract and trap scent molecules, and your nostrils even have slits so you can take big nosefuls of air. Everything is about smell for you. So one day, you stop in your tracks with a revelation. You look at your human owner and you think, "What is it like to have the pitiful, impoverished nose of a human? (Laughter) What is it like when you take a feeble little noseful of air? How can you not know that there's a cat 100 yards away, or that your neighbor was on this very spot six hours ago?" (Laughter)
So because we're humans, we've never experienced that world of smell, so we don't miss it, because we are firmly settled into our umwelt. But the question is, do we have to be stuck there? So as a neuroscientist, I'm interested in the way that technology might expand our umwelt, and how that's going to change the experience of being human.
So we already know that we can marry our technology to our biology, because there are hundreds of thousands of people walking around with artificial hearing and artificial vision. So the way this works is, you take a microphone and you digitize the signal, and you put an electrode strip directly into the inner ear. Or, with the retinal implant, you take a camera and you digitize the signal, and then you plug an electrode grid directly into the optic nerve. And as recently as 15 years ago, there were a lot of scientists who thought these technologies wouldn't work. Why? It's because these technologies speak the language of Silicon Valley, and it's not exactly the same dialect as our natural biological sense organs. But the fact is that it works; the brain figures out how to use the signals just fine.
Now, how do we understand that? Well, here's the big secret: Your brain is not hearing or seeing any of this. Your brain is locked in a vault of silence and darkness inside your skull. All it ever sees are electrochemical signals that come in along different data cables, and this is all it has to work with, and nothing more. Now, amazingly, the brain is really good at taking in these signals and extracting patterns and assigning meaning, so that it takes this inner cosmos and puts together a story of this, your subjective world.
But here's the key point: Your brain doesn't know, and it doesn't care, where it gets the data from. Whatever information comes in, it just figures out what to do with it. And this is a very efficient kind of machine. It's essentially a general purpose computing device, and it just takes in everything and figures out what it's going to do with it, and that, I think, frees up Mother Nature to tinker around with different sorts of input channels.
So I call this the P.H. model of evolution, and I don't want to get too technical here, but P.H. stands for Potato Head, and I use this name to emphasize that all these sensors that we know and love, like our eyes and our ears and our fingertips, these are merely peripheral plug-and-play devices: You stick them in, and you're good to go. The brain figures out what to do with the data that comes in. And when you look across the animal kingdom, you find lots of peripheral devices. So snakes have heat pits with which to detect infrared, and the ghost knifefish has electroreceptors, and the star-nosed mole has this appendage with 22 fingers on it with which it feels around and constructs a 3D model of the world, and many birds have magnetite so they can orient to the magnetic field of the planet. So what this means is that nature doesn't have to continually redesign the brain. Instead, with the principles of brain operation established, all nature has to worry about is designing new peripherals.
Okay. So what this means is this: The lesson that surfaces is that there's nothing really special or fundamental about the biology that we come to the table with. It's just what we have inherited from a complex road of evolution. But it's not what we have to stick with, and our best proof of principle of this comes from what's called sensory substitution. And that refers to feeding information into the brain via unusual sensory channels, and the brain just figures out what to do with it.
Now, that might sound speculative, but the first paper demonstrating this was published in the journal Nature in 1969. So a scientist named Paul Bach-y-Rita put blind people in a modified dental chair, and he set up a video feed, and he put something in front of the camera, and then you would feel that poked into your back with a grid of solenoids. So if you wiggle a coffee cup in front of the camera, you're feeling that in your back, and amazingly, blind people got pretty good at being able to determine what was in front of the camera just by feeling it in the small of their back. Now, there have been many modern incarnations of this. The sonic glasses take a video feed right in front of you and turn that into a sonic landscape, so as things move around, and get closer and farther, it sounds like "Bzz, bzz, bzz." It sounds like a cacophony, but after several weeks, blind people start getting pretty good at understanding what's in front of them just based on what they're hearing. And it doesn't have to be through the ears: this system uses an electrotactile grid on the forehead, so whatever's in front of the video feed, you're feeling it on your forehead. Why the forehead? Because you're not using it for much else.
The most modern incarnation is called the brainport, and this is a little electrogrid that sits on your tongue, and the video feed gets turned into these little electrotactile signals, and blind people get so good at using this that they can throw a ball into a basket, or they can navigate complex obstacle courses. They can come to see through their tongue. Now, that sounds completely insane, right? But remember, all vision ever is is electrochemical signals coursing around in your brain. Your brain doesn't know where the signals come from. It just figures out what to do with them.
So my interest in my lab is sensory substitution for the deaf, and this is a project I've undertaken with a graduate student in my lab, Scott Novich, who is spearheading this for his thesis. And here is what we wanted to do: we wanted to make it so that sound from the world gets converted in some way so that a deaf person can understand what is being said. And we wanted to do this, given the power and ubiquity of portable computing, we wanted to make sure that this would run on cell phones and tablets, and also we wanted to make this a wearable, something that you could wear under your clothing. So here's the concept. So as I'm speaking, my sound is getting captured by the tablet, and then it's getting mapped onto a vest that's covered in vibratory motors, just like the motors in your cell phone. So as I'm speaking, the sound is getting translated to a pattern of vibration on the vest. Now, this is not just conceptual: this tablet is transmitting Bluetooth, and I'm wearing the vest right now. So as I'm speaking -- (Applause) -- the sound is getting translated into dynamic patterns of vibration. I'm feeling the sonic world around me.
So, we've been testing this with deaf people now, and it turns out that after just a little bit of time, people can start feeling, they can start understanding the language of the vest.
So this is Jonathan. He's 37 years old. He has a master's degree. He was born profoundly deaf, which means that there's a part of his umwelt that's unavailable to him. So we had Jonathan train with the vest for four days, two hours a day, and here he is on the fifth day.
Scott Novich: You.
David Eagleman: So Scott says a word, Jonathan feels it on the vest, and he writes it on the board.
SN: Where. Where.
DE: Jonathan is able to translate this complicated pattern of vibrations into an understanding of what's being said.
SN: Touch. Touch.
DE: Now, he's not doing this -- (Applause) -- Jonathan is not doing this consciously, because the patterns are too complicated, but his brain is starting to unlock the pattern that allows it to figure out what the data mean, and our expectation is that, after wearing this for about three months, he will have a direct perceptual experience of hearing in the same way that when a blind person passes a finger over braille, the meaning comes directly off the page without any conscious intervention at all. Now, this technology has the potential to be a game-changer, because the only other solution for deafness is a cochlear implant, and that requires an invasive surgery. And this can be built for 40 times cheaper than a cochlear implant, which opens up this technology globally, even for the poorest countries.
Now, we've been very encouraged by our results with sensory substitution, but what we've been thinking a lot about is sensory addition. How could we use a technology like this to add a completely new kind of sense, to expand the human umvelt? For example, could we feed real-time data from the Internet directly into somebody's brain, and can they develop a direct perceptual experience?
So here's an experiment we're doing in the lab. A subject is feeling a real-time streaming feed from the Net of data for five seconds. Then, two buttons appear, and he has to make a choice. He doesn't know what's going on. He makes a choice, and he gets feedback after one second. Now, here's the thing: The subject has no idea what all the patterns mean, but we're seeing if he gets better at figuring out which button to press. He doesn't know that what we're feeding is real-time data from the stock market, and he's making buy and sell decisions. (Laughter) And the feedback is telling him whether he did the right thing or not. And what we're seeing is, can we expand the human umvelt so that he comes to have, after several weeks, a direct perceptual experience of the economic movements of the planet. So we'll report on that later to see how well this goes. (Laughter)
Here's another thing we're doing: During the talks this morning, we've been automatically scraping Twitter for the TED2015 hashtag, and we've been doing an automated sentiment analysis, which means, are people using positive words or negative words or neutral? And while this has been going on, I have been feeling this, and so I am plugged in to the aggregate emotion of thousands of people in real time, and that's a new kind of human experience, because now I can know how everyone's doing and how much you're loving this. (Laughter) (Applause) It's a bigger experience than a human can normally have.
We're also expanding the umvelt of pilots. So in this case, the vest is streaming nine different measures from this quadcopter, so pitch and yaw and roll and orientation and heading, and that improves this pilot's ability to fly it. It's essentially like he's extending his skin up there, far away.
And that's just the beginning. What we're envisioning is taking a modern cockpit full of gauges and instead of trying to read the whole thing, you feel it. We live in a world of information now, and there is a difference between accessing big data and experiencing it.
So I think there's really no end to the possibilities on the horizon for human expansion. Just imagine an astronaut being able to feel the overall health of the International Space Station, or, for that matter, having you feel the invisible states of your own health, like your blood sugar and the state of your microbiome, or having 360-degree vision or seeing in infrared or ultraviolet.
So the key is this: As we move into the future, we're going to increasingly be able to choose our own peripheral devices. We no longer have to wait for Mother Nature's sensory gifts on her timescales, but instead, like any good parent, she's given us the tools that we need to go out and define our own trajectory. So the question now is, how do you want to go out and experience your universe?
Thank you. Chris Anderson: Can you feel it? DE: Yeah.
Actually, this was the first time I felt applause on the vest. It's nice. It's like a massage. (Laughter)
CA: Twitter's going crazy. Twitter's going mad. So that stock market experiment. This could be the first experiment that secures its funding forevermore, right, if successful?
DE: Well, that's right, I wouldn't have to write to NIH anymore.
CA: Well look, just to be skeptical for a minute, I mean, this is amazing, but isn't most of the evidence so far that sensory substitution works, not necessarily that sensory addition works? I mean, isn't it possible that the blind person can see through their tongue because the visual cortex is still there, ready to process, and that that is needed as part of it?
DE: That's a great question. We actually have no idea what the theoretical limits are of what kind of data the brain can take in. The general story, though, is that it's extraordinarily flexible. So when a person goes blind, what we used to call their visual cortex gets taken over by other things, by touch, by hearing, by vocabulary. So what that tells us is that the cortex is kind of a one-trick pony. It just runs certain kinds of computations on things. And when we look around at things like braille, for example, people are getting information through bumps on their fingers. So I don't thing we have any reason to think there's a theoretical limit that we know the edge of.
CA: If this checks out, you're going to be deluged. There are so many possible applications for this. Are you ready for this? What are you most excited about, the direction it might go? DE: I mean, I think there's a lot of applications here. In terms of beyond sensory substitution, the things I started mentioning about astronauts on the space station, they spend a lot of their time monitoring things, and they could instead just get what's going on, because what this is really good for is multidimensional data. The key is this: Our visual systems are good at detecting blobs and edges, but they're really bad at what our world has become, which is screens with lots and lots of data. We have to crawl that with our attentional systems. So this is a way of just feeling the state of something, just like the way you know the state of your body as you're standing around. So I think heavy machinery, safety, feeling the state of a factory, of your equipment, that's one place it'll go right away.
CA: David Eagleman, that was one mind-blowing talk. Thank you very much.
So,  if you're in the audience today,  or maybe you're watching this talk in some other time  or place,  you are a participant in the digital rights ecosystem.  Whether you're an artist,  a technologist,  a lawyer  or a fan,  the handling of copyright directly impacts your life.  Rights management is no longer simply a question of ownership,  it's a complex web of relationships  and a critical part of our cultural landscape.   YouTube cares deeply about the rights of content owners,  but  in order to give them choices about what they can do with copies,  mashups  and more,  we need to first identify  when copyrighted material is uploaded to our site. 
Let's look at a specific video   so you can see how it works.  Two years ago,  recording artist Chris Brown released the official video of his single "Forever."  A fan saw it on TV,  recorded it with her camera phone,  and uploaded it to YouTube.  Because  Sony Music had registered Chris Brown's video in our Content ID system,  within seconds of attempting to upload the video,  the copy was detected,  giving Sony the choice of what to do next. 
But  how do we know that  the user's video was a copy?  Well,  it starts with content owners delivering assets into our database,  along with a usage policy  that tells us what to do  when we find a match.  We compare each upload against all of the reference files in our database.  This heat map is going to show you  how the brain of the system works.  Here we can see the original reference file  being compared to the user generated content.  The system compares every moment of one to the other to see if there's a match.  This means that  we can identify a match  even if the copy used is  just a portion of the original file,  plays it in slow motion  and has degraded audio  and video quality.  And we do this every time  that a video is uploaded to YouTube.  And that's over 20 hours of video every minute.  When we find a match,  we apply the policy  that the rights owner has set down. 
And the scale  and the speed of this system  is truly breathtaking.  We're not just talking about a few videos,  we're talking about over 100 years of video every day,  between new uploads  and the legacy scans  we regularly do across all of the content on the site.  When we compare those hundred years of video,  we're comparing it against millions of reference files in our database.  It would be like 36,000 people  staring at 36,000 monitors each and every day,  without so much as a coffee break. 
Now,   what do we do when we find a match?  Well,  most rights owners,  instead of blocking,  will allow the copy to be published.  And then they benefit through the exposure,  advertising  and linked sales.  Remember Chris Brown's video "Forever"?  Well,  it had its day in the sun  and then it dropped off the charts,  and that looked like the end of the story,  but  sometime last year,  a young couple got married.  This is their wedding video.   You may have seen it. 
What's amazing about this is,  if the processional of the wedding  was this much fun,  can you imagine  how much fun the reception must have been?  I mean,  who are these people?  I totally want to go to that wedding. 
So  their little wedding video went on  to get over 40 million views.  And instead of Sony blocking,  they allowed the upload to occur.  And they put advertising against it  and linked from it to iTunes.  And the song,  18 months old,  went back to number four on the iTunes charts.  So  Sony is generating revenue from both of these.  And Jill  and Kevin,  the happy couple,  they came back from their honeymoon  and found that  their video had gone crazy viral.  And they've ended up on a bunch of talk shows,  and they've used it as an opportunity to make a difference.  The video's inspired over 26,000 dollars in donations to end domestic violence.  The "JK Wedding Dance"  became so popular that  NBC parodied it on the season finale of " The Office,  " which just goes to show,  it's truly an ecosystem of culture.  Because  it's not just amateurs borrowing from big studios,  but  sometimes big studios borrowing back.
By empowering choice,  we can create a culture of opportunity.  And all it took to change things around  was to allow for choice through rights identification.  So   why has no one ever solved this problem before?  It's because  it's a big problem,  and it's complicated  and messy.  It's not uncommon for a single video  to have multiple rights owners.   There's musical labels.  There's multiple music publishers.  And each of these can vary by country.   There's lots of cases  where we have more than one work mashed together.  So  we have to manage many claims to the same video. 
YouTube's Content ID system addresses all of these cases.  But  the system only works through the participation of rights owners.  If you have content  that others are uploading to YouTube,   you should register in the Content ID system,  and then  you'll have the choice about   how your content is used.   And think carefully about the policies  that you attach to that content.  By simply blocking all reuse,  you'll miss out on new art forms,   new audiences,  new distribution channels  and new revenue streams. 
But  it's not just about dollars  and impressions.  Just look at all the joy  that was spread through progressive rights management  and new technology.  And I think  we can all agree that  joy is definitely an idea worth spreading. 

In two weeks time,   that's the ninth anniversary of the day   I first stepped out onto that hallowed "Jeopardy" set.   I mean,   nine years is a long time.   And given "Jeopardy's" average demographics,   I think what that means is  most of the people who saw me on that show are now dead.   But not all,  a few are still alive.  Occasionally I still get recognized at the mall or whatever.   And when I do,   it's as a bit of a know-it-all.    I think that ship has sailed,  it's too late for me.   For better or for worse,  that's what I'm going to be known as,  as the guy who knew a lot of weird stuff. \
And I can't complain about this.  I feel like that was always sort of my destiny,   although I had for many years been pretty deeply in the trivia closet.   If nothing else,   you realize very quickly as a teenager,   it is not a hit with girls to know Captain Kirk's middle name.  And as a result,  I was sort of the deeply closeted kind of know-it-all  for many years.   But if you go further back,  if you look at it,  it's all there.   I was the kind of kid  who was always bugging Mom and Dad  with whatever great fact I had just read about -- Haley's comet or giant squids or the size of the world's biggest pumpkin pie or whatever it was.  I now have a 10-year-old of my own  who's exactly the same.  And I know  how deeply annoying it is,  so karma does work.  \
And I loved game shows,  fascinated with game shows.   I remember crying on my first day of kindergarten back in 1979  because it had just hit me,  as badly as I wanted to go to school,  that I was also going to miss "Hollywood Squares" and  "Family Feud."    I was going to miss my game shows.   And later,  in the mid-'80s,   when "Jeopardy" came back on the air,  I remember running home from school every day  to watch the show.   It was my favorite show,   even before it paid for my house.    And we lived overseas,   we lived in South Korea  where my dad was working,  where there was only one English language TV channel.   There was Armed Forces TV,  and if you didn't speak Korean,  that's what you were watching.   So me and all my friends would run home every day and watch   "Jeopardy."\
I was always that kind of obsessed trivia kid.  I remember being able to play Trivial Pursuit  against my parents  back in the '80s  and holding my own,  back when that was a fad.   There's a weird sense of mastery    you get when you know some bit of boomer trivia  that Mom and Dad don't know.  You know some Beatles factoid  that Dad didn't know.   And you think  knowledge really is power   -- the right fact deployed at exactly the right place. \
I never had a guidance counselor   who thought this was a legitimate career path,   that thought you could major in trivia  or be a professional ex-game show contestant.   And so  I sold out way too young.  I didn't try to figure out   what one does with that.  I studied computers  because I heard  that was the thing,  and I became a computer programmer  -- not an especially good one,  not an especially happy one at the time  when I was first on "Jeopardy" in 2004.  But that's what I was doing. \
And it made it doubly ironic  -- my computer background  -- a few years later,   I think 2009 or so,  when I got another phone call from "Jeopardy" saying,   "It's early days yet,  but IBM tells us  they want to build a supercomputer  to beat you at 'Jeopardy.'   Are you up for this?"   This was the first  I'd heard of it.  And of course I said yes,   for several reasons.  One,  because playing "Jeopardy" is a great time.   It's fun.   It's the most fun  you can have with your pants on.   And I would do it for nothing.   I don't think  they know that,  luckily,  but I would go back  and play for Arby's coupons.   I just love "Jeopardy,"  and I always have.  And second of all,   because I'm a nerdy guy  and this seemed like the future.   People playing computers on game shows   was the kind of thing  I always imagined  would happen in the future,  and now  I could be on the stage with it.   I was not going to say no. \
The third reason I said yes  is because   I was pretty confident that  I was going to win.   I had taken some artificial intelligence classes.   I knew there were no computers  that could do  what you need to do to win on "Jeopardy."  People don't realize how tough it is  to write that kind of program  that can read a "Jeopardy" clue  in a natural language like English  and understand all the double meanings,   the puns,  the red herrings,  unpack the meaning of the clue.   The kind of thing  that a three- or four-year-old human,  little kid could do,  very hard for a computer.  And I thought,  well this is going to be child's play.   Yes, I will come destroy the computer  and defend my species. \
But as the years went on,  as IBM started throwing money  and manpower  and processor speed at this,  I started to get occasional updates from them,  and I started to get a little more worried.  I remember a journal article  about this new question answering software  that had a graph.  It was a scatter chart  showing performance on "Jeopardy,"   tens of thousands of dots representing "Jeopardy" champions  up at the top  with their performance plotted on number of  -- I was going to say questions answered,  but answers questioned,  I guess,  clues responded to -- versus the accuracy of those answers.   So there's a certain performance level   that the computer would need to get to.  And at first,  it was very low.   There was no software  that could compete at this kind of arena.  But  then you see  the line start to go up.  And it's getting very close  to what they call the winner's cloud.   And I noticed in the upper right of the scatter chart  some darker dots,  some black dots,  that were a different color.  And thought,  what are these?   "The black dots in the upper right  represent 74-time 'Jeopardy' champion Ken Jennings. " And I saw this line coming for me.  And I realized,  this is it.   This is what it looks like  when the future comes for you.   It's not the Terminator's gun sight;   it's a little line  coming closer and closer to the thing you can do,   the only thing  that makes you special,  the thing you're best at.\
And when the game eventually happened about a year later,  it was very different  than the "Jeopardy" games  I'd been used to.  We were not playing in L.A.   on the regular "Jeopardy" set.  Watson does not travel.  Watson's actually huge.  It's thousands of processors,   a terabyte of memory,  trillions of bytes of memory.  We got to walk through his climate  -controlled server room.  The only other "Jeopardy" contestant to this day  I've ever been inside.  And so  Watson does not travel.  You must come to it;  you must make the pilgrimage.\
So me and the other human player  wound up at this secret IBM research lab  in the middle of these snowy woods in Westchester County  to play the computer.  And we realized right away that  the computer had a big home court advantage.  There was a big Watson logo  in the middle of the stage.  Like you're going to play the Chicago Bulls,  and there's the thing in the middle of their court.  And the crowd was full of IBM V.P.s   and programmers cheering on their little darling,  having poured millions of dollars  into this hoping against hope  that the humans screw up,  and holding up "Go Watson" signs  and just applauding like pageant moms  every time their little darling got one right.  I think guys had "W-A-T-S-O-N"  written on their bellies in grease paint.  If you can imagine computer programmers  with the letters "W-A-T-S-O-N"  written on their gut,  it's an unpleasant sight.\
But they were right.  They were exactly right.   I don't want to spoil it,  if you still have this sitting on your DVR,  but Watson won handily.  And I remember  standing there behind the podium  as I could hear that  little insectoid thumb clicking.  It had a robot thumb  that was clicking on the buzzer.  And you could hear that little tick,  tick,  tick,  tick.  And I remember thinking,  this is it.  I felt obsolete.  I felt like a Detroit factory worker of the '80s  seeing a robot  that could now do his job on the assembly line.   I felt like  quiz show contestant was now the first job  that had become obsolete  under this new regime of thinking computers.  And it hasn't been the last.\
If you watch the news,  you'll see occasionally  -- and I see this all the time  -- that pharmacists now,  there's a machine  that can fill prescriptions automatically  without actually needing a human pharmacist.   And a lot of law firms are getting rid of paralegals  because there's software  that can sum up case laws  and legal briefs  and decisions.  You don't need human assistants for that anymore.  I read the other day about a program  where you feed it a box score  from a baseball or football game  and it spits out a news article  as if a human had watched the game  and was commenting on it.  And obviously these new technologies can't do  as clever or creative a job  as the humans they're replacing,  but they're faster,  and crucially,  they're much,  much cheaper.   So it makes me wonder  what the economic effects of this might be.  I've read economists saying that  as a result of these new technologies,  we'll enter a new golden age of leisure  when we'll all have time  for the things  we really love  because all these onerous tasks will be taken over by Watson   and his digital brethren.  I've heard other people say quite the opposite,  that this is yet another tier of the middle class  that's having the thing  they can do taken away from them  by a new technology  and that  this is actually something ominous,  something that we should worry about. \
I'm not an economist myself.   All I know is  how it felt to be the guy  put out of work.  And it was friggin' demoralizing.  It was terrible.  Here's the one thing  that I was ever good at,  and all it took was IBM pouring tens of millions of dollars  and its smartest people  and thousands of processors  working in parallel  and they could do the same thing.  They could do it a little bit faster  and a little better on national TV,   and "I'm sorry,   Ken.  We don't need you anymore.  " And it made me think,  what does this mean,  if we're going to be able to start outsourcing,  not just lower unimportant brain functions.   I'm sure many of you remember a distant time  when we had to know phone numbers,  when we knew our friends' phone numbers.  And suddenly   there was a machine that did that,   and now we don't need to remember that anymore.  I have read that  there's now actually evidence that  the hippocampus,  the part of our brain  that handles spacial relationships,  physically shrinks  and atrophies in people  who use tools like GPS,  because we're not exercising our sense of direction anymore.  We're just obeying a little talking voice  on our dashboard.  And as a result,   a part of our brain  that's supposed to do that kind of stuff   gets smaller and dumber.   And it made me think,   what happens  when computers are now better at knowing   and remembering stuff than we are?  Is all of our brain going to start to shrink  and atrophy like that?  Are we as a culture  going to start to value knowledge less?   As somebody  who has always believed in the importance of the stuff  that we know,  this was a terrifying idea to me.\
The more I thought about it,  I realized,  no,  it's still important. The things we know are   still important.   I came to believe  there were two advantages  that those of us  who have these things in our head  have over somebody who says,  "Oh,  yeah.  I can Google that.   Hold on a second. " There's an advantage of volume,  and there's an advantage of time. \
The advantage of volume,   first,  just has to do with the complexity of the world nowadays.  There's so much information out there.  Being a Renaissance man  or woman,  that's something that was only possible in the Renaissance.  Now it's really not possible to be reasonably educated  on every field of human endeavor.  There's just too much.  They say that the scope of human information is now doubling every 18 months or so,   the sum total of human information.  That means between now and late 2014,   we will generate as much information,   in terms of gigabytes,  as all of humanity has in all the previous millenia put together.  It's doubling every 18 months now.  This is terrifying because a lot of the big decisions we make  require the mastery of lots of different kinds of facts.  A decision like where do I go to school?  What should I major in?  Who do I vote for?  Do I take this job or that one?   These are the decisions  that require correct judgments about many different kinds of facts.  If we have those facts at our mental fingertips,   we're going to be able to make informed decisions.   If,  on the other hand,   we need to look them all up,  we may be in trouble.   According to a National Geographic survey I just saw,  somewhere along the lines of 80 percent of the people  who vote in a U.S. presidential election  about issues like foreign policy  cannot find Iraq or Afghanistan on a map.    If you can't do that first step,  are you really going to look up the other thousand facts  you're going to need to know to master your knowledge of U.S. foreign policy?  Quite probably not.  At some point you're just going to be like,  "You know what?  There's too much to know.  Screw it."  And you'll make a less informed decision. \
The other issue is the advantage of time that you have  if you have all these things at your fingertips.   I always think of the story of a little girl  named Tilly Smith.   She was a 10-year-old girl from Surrey,  England on vacation with her parents a few years ago in Phuket,  Thailand.  She runs up to them on the beach one morning  and says,   "Mom,  Dad,  we've got to get off the beach."  And they say,  "What do you mean?  We just got here.  " And she said,  "In Mr. Kearney's geography class last month,  he told us that  when the tide goes out abruptly out to sea  and you see the waves churning way out there,  that's the sign of a tsunami,  and you need to clear the beach. " What would you do  if your 10-year-old daughter came up to you with this?   Her parents thought about it,  and they finally,   to their credit,  decided to believe her.  They told the lifeguard,  they went back to the hotel,  and the lifeguard cleared over 100 people off the beach,  luckily,  because that was the day of the Boxing Day tsunami,  the day after Christmas,  2004,   that killed thousands of people in Southeast Asia  and around the Indian Ocean.  But not on that beach,  not on Mai Khao Beach,  because this little girl had remembered one fact  from her geography teacher a month before.\
Now when facts come in handy like that  -- I love that story  because it shows you the power of one fact,  one remembered fact in exactly the right place at the right time  -- normally something that's easier to see on game shows  than in real life.   But in this case  it happened in real life.  And it happens in real life all the time.  It's not always a tsunami,  often it's a social situation.  It's a meeting  or job interview  or first date  or some relationship  that gets lubricated  because two people realize  they share some common piece of knowledge.  You say where you're from,  and I say,  "Oh,  yeah.  " Or your alma mater  or your job,  and I know just a little something about it,  enough to get the ball rolling.  People love that shared connection  that gets created  when somebody knows something about you.  It's like they took the time to get to know you  before you even met.  That's often the advantage of time.   And it's not effective  if you say,  "Well,  hold on.  You're from Fargo,  North Dakota.  Let me see what comes up.  Oh,   yeah.  Roger Maris was from Fargo.  " That doesn't work.  That's just annoying.   \
The great 18th-century British theologian  and thinker,  friend of Dr. Johnson,  Samuel Parr  once said,  "It's always better to know a thing  than not to know it.  " And if I have lived my life by any kind of creed,  it's probably that.  I have always believed that  the things we know  -- that knowledge is an absolute good,   that the things we have learned  and carry with us in our heads  are what make us who we are,  as individuals  and as a species.  I don't know if I want to live in a world  where knowledge is obsolete.  I don't want to live in a world  where cultural literacy has been replaced by these little bubbles of specialty,  so that none of us know about the common associations  that used to bind our civilization together.  I don't want to be the last trivia know-it-all  sitting on a mountain somewhere,  reciting to himself the state capitals  and the names of "Simpsons" episodes  and the lyrics of Abba songs.  I feel like our civilization works  when this is a vast cultural heritage  that we all share  and that we know without having to outsource it to our devices,  to our search engines and  our smartphones. \
In the movies,  when computers like Watson start to think,  things don't always end well.  Those movies are never about beautiful utopias.  It's always a terminator  or a matrix  or an astronaut getting sucked out an airlock in "2001."  Things always go terribly wrong.  And I feel like  we're sort of at the point now  where we need to make that choice of  what kind of future we want to be living in.  This is a question of leadership,  because it becomes a question of who leads the future.  On the one hand,  we can choose between a new golden age  where information is more universally available  than it's ever been in human history,  where we all have the answers to our questions at our fingertips.  And on the other hand,  we have the potential to be living in some gloomy dystopia  where the machines have taken over  and we've all decided  it's not important what we know anymore,  that knowledge isn't valuable  because it's all out there in the cloud,  and why would we ever bother learning anything new. \
Those are the two choices we have.  I know which future I would rather be living in.   And we can all make that choice.  We make that choice by being curious,  inquisitive people  who like to learn,  who don't just say,  "Well,  as soon as the bell has rung  and the class is over,  I don't have to learn anymore,  " or "Thank goodness  I have my diploma.  I'm done learning for a lifetime.  I don't have to learn new things anymore.  "  No,  every day we should be striving to learn something new.  We should have this unquenchable curiosity for the world around us.  That's where the people you see on "Jeopardy" come from.  These know-it-alls,  they're not Rainman-style savants  sitting at home  memorizing the phone book.  I've met a lot of them.  For the most part,   they are just normal folks  who are universally interested in the world around them,  curious about everything,  thirsty for this knowledge about whatever subject. \
We can live in one of these two worlds.  We can live in a world  where our brains,  the things that we know,  continue to be the thing that makes us special,  or a world in which  we've outsourced all of that to evil supercomputers from the future  like Watson.  Ladies and  gentlemen,  the choice is yours. \
}I'm really excited to share with you some findings  that really surprise me about  what makes companies succeed the most,  what factors actually matter the most for startup success. 
I believe that  the startup organization is one of the greatest forms to make the world a better place.  If you take a group of people  with the right equity incentives  and organize them in a startup,  you can unlock human potential in a way never before possible.  You get them to achieve unbelievable things. 
But  if the startup organization is so great,  why do so many fail?  That's what I wanted to find out.  I wanted to find out  what actually matters most for startup success. 
And I wanted to try to be systematic about it,  avoid some of my instincts  and maybe misperceptions  I have from so many companies I've seen over the years. 
I wanted to know this because  I've been starting businesses since I was 12 years old  when I sold candy at the bus stop in junior high school,  to high school,  when I made solar energy devices,  to college,  when I made loudspeakers.  And when I graduated from college,  I started software companies.  And 20 years ago,  I started Idealab,  and in the last 20 years,  we started more than 100 companies,  many successes,   and many big failures.  We learned a lot from those failures. 
So I tried to look across  what factors accounted the most for company success  and failure.  So I looked at these five.  First,  the idea.  I used to think that  the idea was everything.  I named my company Idealab  for how much I worship the "aha!" moment  when you first come up with the idea.  But  then over time,  I came to think that  maybe the team,  the execution,  adaptability,  that mattered even more than the idea. 
I never thought  I'd be quoting boxer Mike Tyson on the TED stage,  but he once said,  "Everybody has a plan,  until they get punched in the face."   And I think  that's so true about business as well.  So much about a team's execution is  its ability to adapt to getting punched in the face by the customer.   The customer is the true reality.  And that's why  I came to think that  the team maybe was the most important thing. 
Then I started looking at the business model.  Does the company have a very clear path generating customer revenues?  That started rising to the top in my thinking about maybe  what mattered most for success. 
Then I looked at the funding.  Sometimes companies received intense amounts of funding.  Maybe that's the most important thing? 
And then of course,  the timing.  Is the idea way too early  and the world's not ready for it?  Is it early,  as in,  you're in advance  and you have to educate the world?  Is it just right?  Or is it too late,  and there's already too many competitors? 
So I tried to look very carefully at these five factors across many companies.  And I looked across all 100 Idealab companies,  and 100 non-Idealab companies to try  and come up with something scientific about it. 
So first,  on these Idealab companies,  the top five companies  -- Citysearch,   CarsDirect,  GoTo,  NetZero,   Tickets.com  -- those all became billion-dollar successes.   And the five companies on the bottom  -- Z.com,  Insider Pages,  MyLife,  Desktop Factory,  Peoplelink  -- we all had high hopes for,  but didn't succeed. 
So I tried to rank across all of those attributes  how I felt those companies scored on each of those dimensions.   And then for non-Idealab companies,   I looked at wild successes,   like Airbnb  and Instagram  and  Uber  and Youtube   and LinkedIn. 
And some failures:  Webvan,  Kozmo,  Pets.com Flooz  and Friendster.  The bottom companies had intense funding,   they even had business models in some cases,  but they didn't succeed.   I tried to look at what factors actually accounted the most for success  and failure across all of these companies,  and the results really surprised me. 
The number one thing was timing.  Timing accounted for 42 percent of the difference between success and failure.   Team and execution came in second,  and the idea,  the differentiability of the idea,   the uniqueness of the idea,    that actually came in third. 
Now,  this isn't absolutely definitive,    it's not to say that the idea isn't important,   but it very much surprised me that  the idea wasn't the most important thing.  Sometimes it mattered more  when it was actually timed. 
The last two,  business model  and funding,  made sense to me actually.  I think business model makes sense to be that low  because you can start out without a business model   and add one later if your customers are demanding  what you're creating.  And funding,  I think as well,  if you're underfunded at first  but  you're gaining traction,  especially in today's age,  it's very,  very easy to get intense funding. 
So now let me give you some specific examples about each of these.  So take a wild success like Airbnb  that everybody knows about.  Well,  that company was famously passed on by many smart investors  because people thought,  "No one's going to rent out a space in their home to a stranger."   Of course,  people proved that wrong.  But one of the reasons it succeeded,   aside from a good business model,   a good idea,   great execution,   is the timing. 
That company came out right during the height of the recession  when people really needed extra money,   and that maybe helped people overcome their objection to renting out their own home to a stranger. 
Same thing with Uber.   Uber came out,   incredible company,  incredible business model,  great execution,  too.  But the timing was so perfect for their need to get drivers into the system.   Drivers were looking for extra money;  it was very,   very important. 
Some of our early successes,   Citysearch,   came out when people needed web pages.   GoTo.com,  which we announced actually at TED in 1998,  was when companies were looking for cost-effective ways to get traffic.  We thought the idea was so great,  but actually,  the timing was probably maybe more important.   And then some of our failures.   We started a company called Z.com,   it was an online entertainment company.   We were so excited about it  -- we raised enough money,  we had a great business model,  we even signed incredibly great Hollywood talent to join the company.  But  broadband penetration was too low in 1999-2000.   It was too hard to watch video content online,   you had to put codecs in your browser   and do all this stuff,  and the company eventually went out of business in 2003. 
Just two years later,   when the codec problem was solved by Adobe Flash  and when broadband penetration crossed 50 percent in America,   YouTube was perfectly timed.   Great idea,  but unbelievable timing.   In fact,  YouTube didn't even have a business model   when it first started.   It wasn't even certain that   that would work out.  But  that was beautifully,  beautifully timed. 
So what I would say,  in summary,  is execution definitely matters a lot.   The idea matters a lot.  But  timing might matter even more.  And the best way to really assess timing is  to really look at  whether consumers are really ready for what you have to offer them.  And to be really,  really honest about it,  not be in denial about any results that you see,  because  if you have something you love,   you want to push it forward,  but  you have to be very,  very honest about that factor on timing. 
As I said earlier,   I think startups can change the world  and make the world a better place.   I hope some of these insights   can maybe help you have a slightly higher success ratio,  and thus make something great come to the world  that wouldn't have happened otherwise. 
Thank you very much,   you've been a great audience. 

My students  and I work on very tiny robots.  Now,  you can think of these as robotic versions of something  that you're all very familiar with:  an ant.  We all know that  ants   and other insects at this size scale  can do some pretty incredible things.  We've all seen a group of ants,  or some version of that,  carting off your potato chip at a picnic,  for example. 
But  what are the real challenges of engineering these ants?  Well,  first of all,   how do we get the capabilities of an ant in a robot at the same size scale?  Well,  first  we need to figure out how to make them move  when they're so small.  We need mechanisms like   legs  and efficient motors  in order to  support that locomotion,  and we need the sensors,  power  and control in order to pull everything together in a semi-intelligent ant robot.  And finally,  to make these things really functional,  we want a lot of them working together in order to do bigger things. 
So I'll start with mobility.  Insects move around amazingly well.  This video is from UC Berkeley.  It shows a cockroach moving over incredibly rough terrain  without tipping over,  and it's able to do this  because  its legs are a combination of rigid materials,  which is what  we traditionally use to make robots,  and soft materials.  Jumping is another really interesting way to get around  when you're very small.  So these insects store energy in a spring  and release that really quickly  to get the high power they need to jump out of water,  for example. 
So one of the big contributions from my lab  has been to combine rigid  and soft materials in very,  very small mechanisms.  So this jumping mechanism  is about four millimeters on a side,  so really tiny.  The hard material here is silicon,  and the soft material is silicone rubber.  And the basic idea is that  we're going to compress this,  store energy in the springs,  and then release it to jump.  So there's no motors on board this right now,  no power.  This is actuated with a method  that we call in my lab  "graduate student with tweezers."  So what you'll see in the next video  is this guy  doing amazingly well for its jumps.  So this is Aaron,  the graduate student in question,  with the tweezers,   and what you see is  this four-millimeter-sized mechanism jumping almost 40 centimeters high.  That's almost 100 times its own length.  And it survives,  bounces on the table,  it's incredibly robust,  and of course  survives quite well until we lose it  because it's very tiny. 
Ultimately,  though,  we want to add motors to this too,  and we have students in the lab working on millimeter-sized motors  to eventually integrate onto small,  autonomous robots.  But  in order to look at mobility  and locomotion  at this size scale to start,   we're cheating  and using magnets.  So this shows  what would eventually be part of a micro-robot leg,  and you can see the silicone rubber joints  and there's an embedded magnet  that's being moved around by an external magnetic field. 
So this leads to the robot  that I showed you earlier.  The really interesting thing  that this robot can help us figure out  is how insects move at this scale.  We have a really good model  for how everything from a cockroach up to an elephant moves.  We all move in this kind of bouncy way  when we run.  But  when I'm really small,  the forces between my feet  and the ground are going to affect my locomotion a lot more than my mass,  which is what causes that bouncy motion.  So this guy doesn't work quite yet,  but  we do have slightly larger versions that do run around.  So this is about a centimeter cubed,  a centimeter on a side,  so very tiny,  and we've gotten this to run about 10 body lengths per second,  so 10 centimeters per second.  It's pretty quick for a little,  small guy,  and that's really only limited by our test setup.  But  this gives you some idea of how it works right now.  We can also make 3D-printed versions of this  that can climb over obstacles,  a lot like the cockroach  that you saw earlier. 
Ultimately  we want to add everything onboard the robot.  We want sensing,  power,  control,  actuation all together,  and not everything needs to be bio-inspired.  So  this robot's about the size of a Tic Tac.  And in this case,  instead of magnets or muscles to move this around,  we use rockets.  So  this is a micro-fabricated energetic material,  and we can create tiny pixels of this,  and we can put one of these pixels on the belly of this robot,  and this robot,  then,  is going to jump  when it senses an increase in light. 
So  the next video is one of my favorites.  So  you have this 300-milligram robot jumping about eight centimeters in the air.  It's only four by four by seven millimeters in size.  And you'll see a big flash at the beginning  when the energetic is set off,  and the robot tumbling through the air.  So  there was that big flash,  and you can see the robot jumping up through the air.  So there's no tethers on this,  no wires connecting to this.  Everything is onboard,  and it jumped in response to the student  just flicking on a desk lamp next to it.
So  I think you can imagine all the cool things  that we could do with robots  that can run  and crawl  and jump  and roll at this size scale.  Imagine the rubble  that you get after a natural disaster  like an earthquake.  Imagine these small robots running through that rubble  to look for survivors.  Or imagine a lot of small robots running around a bridge  in order to inspect it  and make sure it's safe  so you don't get collapses like this,  which happened outside of Minneapolis in 2007.  Or just imagine  what you could do  if you had robots  that could swim through your blood.  Right?  "Fantastic Voyage,"  Isaac Asimov.  Or they could operate  without having to cut you open in the first place. Or we could radically change the way we build things  if we have our tiny robots work the same way  that termites do,  and they build these incredible eight-meter-high mounds,  effectively well ventilated apartment buildings  for other termites in Africa  and Australia. 
So I think  I've given you some of the possibilities  of what we can do with these small robots.  And  we've made some advances so far,  but  there's still a long way to go,  and hopefully some of you can contribute to that destination. 